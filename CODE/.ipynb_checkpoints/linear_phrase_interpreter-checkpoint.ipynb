{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Admiration</th>\n",
       "      <th>Adoration</th>\n",
       "      <th>Aesthetic Appreciation</th>\n",
       "      <th>Amusement</th>\n",
       "      <th>Anger</th>\n",
       "      <th>Anxiety</th>\n",
       "      <th>Awe</th>\n",
       "      <th>Awkwardness</th>\n",
       "      <th>Boredom</th>\n",
       "      <th>...</th>\n",
       "      <th>vitality</th>\n",
       "      <th>vulnerability</th>\n",
       "      <th>warmth</th>\n",
       "      <th>weakness</th>\n",
       "      <th>weariness</th>\n",
       "      <th>wonder</th>\n",
       "      <th>worry</th>\n",
       "      <th>wrath</th>\n",
       "      <th>yearning</th>\n",
       "      <th>zeal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001.mp4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002.mp4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.25000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0003.mp4</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.66667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0004.mp4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.75000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.11111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0005.mp4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333330</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.11111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 649 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Filename  Admiration  Adoration  Aesthetic Appreciation  Amusement  \\\n",
       "0  0001.mp4    0.000000        0.0                0.083333    0.00000   \n",
       "1  0002.mp4    0.000000        0.0                0.000000    0.25000   \n",
       "2  0003.mp4    0.083333        0.0                0.083333    0.66667   \n",
       "3  0004.mp4    0.000000        0.0                0.000000    0.75000   \n",
       "4  0005.mp4    0.000000        0.0                0.000000    0.00000   \n",
       "\n",
       "      Anger   Anxiety       Awe  Awkwardness   Boredom  ...   vitality  \\\n",
       "0  0.083333  0.083333  0.083333     0.000000  0.000000  ...        0.0   \n",
       "1  0.000000  0.000000  0.000000     0.000000  0.083333  ...        0.0   \n",
       "2  0.000000  0.000000  0.000000     0.083333  0.000000  ...        0.0   \n",
       "3  0.000000  0.000000  0.000000     0.083333  0.000000  ...        0.0   \n",
       "4  0.000000  0.333330  0.000000     0.000000  0.000000  ...        0.0   \n",
       "\n",
       "   vulnerability  warmth  weakness  weariness  wonder    worry  wrath  \\\n",
       "0            0.0     0.0       0.0    0.00000     0.0  0.00000    0.0   \n",
       "1            0.0     0.0       0.0    0.00000     0.0  0.00000    0.0   \n",
       "2            0.0     0.0       0.0    0.00000     0.0  0.00000    0.0   \n",
       "3            0.0     0.0       0.0    0.11111     0.0  0.00000    0.0   \n",
       "4            0.0     0.0       0.0    0.00000     0.0  0.11111    0.0   \n",
       "\n",
       "   yearning  zeal  \n",
       "0       0.0   0.0  \n",
       "1       0.0   0.0  \n",
       "2       0.0   0.0  \n",
       "3       0.0   0.0  \n",
       "4       0.0   0.0  \n",
       "\n",
       "[5 rows x 649 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os.path\n",
    "root_path = os.path.dirname(os.getcwd())\n",
    "\n",
    "# Import video data (thanks Cowen & Keltner!)\n",
    "video_data = pd.read_csv(os.path.join(root_path, 'DATA/video_data.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate out 34 emotion category scores, downcase column names\n",
    "# Fraction of respondents who chose from multiple-select\n",
    "video_category_data = video_data.iloc[:, 1:35]\n",
    "video_category_data.index = video_data['Filename']\n",
    "\n",
    "# Separate out 14 affective dimension scores\n",
    "# 1-9 ratings\n",
    "video_dimension_data = video_data.iloc[:, 35:49]\n",
    "video_dimension_data.index = video_data['Filename']\n",
    "\n",
    "# Separate 600 free response term scores\n",
    "# Fraction of respondants who chose from multiple-select dropdown\n",
    "video_term_data = video_data.iloc[:, 49:]\n",
    "video_term_data.index = video_data['Filename']\n",
    "\n",
    "# Select distinct category scores\n",
    "# Subset of category scores\n",
    "video_distinct_category_data = video_data[[\n",
    "    'Admiration',\n",
    "    'Adoration',\n",
    "    'Aesthetic Appreciation',\n",
    "    'Amusement',\n",
    "    'Anger',\n",
    "    'Anxiety',\n",
    "    'Awe',\n",
    "    'Awkwardness',\n",
    "    'Boredom',\n",
    "    'Calmness',\n",
    "    'Confusion',\n",
    "    'Craving',\n",
    "    'Disgust',\n",
    "    'Empathic Pain',\n",
    "    'Entrancement',\n",
    "    'Excitement',\n",
    "    'Fear',\n",
    "    'Horror',\n",
    "    'Interest',\n",
    "    'Joy',\n",
    "    'Nostalgia',\n",
    "    'Relief',\n",
    "    'Romance',\n",
    "    'Sadness',\n",
    "    'Satisfaction',\n",
    "    'sexual desire',\n",
    "    'Surprise'\n",
    "]]\n",
    "video_distinct_category_data.index = video_data['Filename']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data supported matrices (v_to_c.dot(video_vector) = other_vector)\n",
    "v_to_c = video_category_data.transpose()\n",
    "v_to_d = video_dimension_data.transpose()\n",
    "v_to_t = video_term_data.transpose()\n",
    "v_to_dc = video_distinct_category_data.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inverse matrices\n",
    "c_to_v = pd.DataFrame(np.linalg.pinv(v_to_c.values), v_to_c.columns, v_to_c.index)\n",
    "d_to_v = pd.DataFrame(np.linalg.pinv(v_to_d.values), v_to_d.columns, v_to_d.index)\n",
    "t_to_v = pd.DataFrame(np.linalg.pinv(v_to_t.values), v_to_t.columns, v_to_t.index)\n",
    "dc_to_v = pd.DataFrame(np.linalg.pinv(v_to_dc.values), v_to_dc.columns, v_to_dc.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Category inference matrices\n",
    "c_to_d = v_to_d.dot(c_to_v)\n",
    "c_to_t = v_to_t.dot(c_to_v)\n",
    "c_to_dc = v_to_dc.dot(c_to_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimension inference matrices\n",
    "d_to_c = v_to_c.dot(d_to_v)\n",
    "d_to_t = v_to_t.dot(d_to_v)\n",
    "d_to_dc = v_to_dc.dot(d_to_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Term inference matrices\n",
    "t_to_c = v_to_c.dot(t_to_v)\n",
    "t_to_d = v_to_d.dot(t_to_v)\n",
    "t_to_dc = v_to_dc.dot(t_to_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distinct category inference matrices\n",
    "dc_to_c = v_to_c.dot(dc_to_v)\n",
    "dc_to_d = v_to_d.dot(dc_to_v)\n",
    "dc_to_t = v_to_t.dot(dc_to_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in /home/russell/anaconda3/lib/python3.6/site-packages (2.0.12)\n",
      "Requirement already satisfied: numpy>=1.7 in /home/russell/.local/lib/python3.6/site-packages (from spacy) (1.15.2)\n",
      "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /home/russell/anaconda3/lib/python3.6/site-packages (from spacy) (0.9.6)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/russell/anaconda3/lib/python3.6/site-packages (from spacy) (2.18.4)\n",
      "Requirement already satisfied: murmurhash<0.29,>=0.28 in /home/russell/anaconda3/lib/python3.6/site-packages (from spacy) (0.28.0)\n",
      "Requirement already satisfied: regex==2017.4.5 in /home/russell/anaconda3/lib/python3.6/site-packages (from spacy) (2017.4.5)\n",
      "Requirement already satisfied: dill<0.3,>=0.2 in /home/russell/anaconda3/lib/python3.6/site-packages (from spacy) (0.2.8.2)\n",
      "Requirement already satisfied: thinc<6.11.0,>=6.10.3 in /home/russell/anaconda3/lib/python3.6/site-packages (from spacy) (6.10.3)\n",
      "Requirement already satisfied: preshed<2.0.0,>=1.0.0 in /home/russell/anaconda3/lib/python3.6/site-packages (from spacy) (1.0.1)\n",
      "Requirement already satisfied: ujson>=1.35 in /home/russell/anaconda3/lib/python3.6/site-packages (from spacy) (1.35)\n",
      "Requirement already satisfied: cymem<1.32,>=1.30 in /home/russell/anaconda3/lib/python3.6/site-packages (from spacy) (1.31.2)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/russell/anaconda3/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in /home/russell/anaconda3/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.6)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /home/russell/anaconda3/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.22)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/russell/anaconda3/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2018.4.16)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /home/russell/anaconda3/lib/python3.6/site-packages (from thinc<6.11.0,>=6.10.3->spacy) (4.26.0)\n",
      "Requirement already satisfied: msgpack-numpy<1.0.0,>=0.4.1 in /home/russell/anaconda3/lib/python3.6/site-packages (from thinc<6.11.0,>=6.10.3->spacy) (0.4.4.1)\n",
      "Requirement already satisfied: six<2.0.0,>=1.10.0 in /home/russell/.local/lib/python3.6/site-packages (from thinc<6.11.0,>=6.10.3->spacy) (1.11.0)\n",
      "Requirement already satisfied: msgpack<1.0.0,>=0.5.6 in /home/russell/anaconda3/lib/python3.6/site-packages (from thinc<6.11.0,>=6.10.3->spacy) (0.5.6)\n",
      "Requirement already satisfied: cytoolz<0.10,>=0.9.0 in /home/russell/anaconda3/lib/python3.6/site-packages (from thinc<6.11.0,>=6.10.3->spacy) (0.9.0.1)\n",
      "Requirement already satisfied: wrapt<1.11.0,>=1.10.0 in /home/russell/anaconda3/lib/python3.6/site-packages (from thinc<6.11.0,>=6.10.3->spacy) (1.10.11)\n",
      "Requirement already satisfied: toolz>=0.8.0 in /home/russell/anaconda3/lib/python3.6/site-packages (from cytoolz<0.10,>=0.9.0->thinc<6.11.0,>=6.10.3->spacy) (0.9.0)\n",
      "\u001b[31mtensorflow 1.11.0 has requirement setuptools<=39.1.0, but you'll have setuptools 40.4.3 which is incompatible.\u001b[0m\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: en_core_web_md==2.0.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_md-2.0.0/en_core_web_md-2.0.0.tar.gz#egg=en_core_web_md==2.0.0 in /home/russell/anaconda3/lib/python3.6/site-packages (2.0.0)\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\n",
      "\u001b[93m    Linking successful\u001b[0m\n",
      "    /home/russell/anaconda3/lib/python3.6/site-packages/en_core_web_md -->\n",
      "    /home/russell/anaconda3/lib/python3.6/site-packages/spacy/data/en_core_web_md\n",
      "\n",
      "    You can now load the model via spacy.load('en_core_web_md')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SLOW IF FIRST TIME\n",
    "# Install and import Spacy natural language utility\n",
    "!pip install spacy\n",
    "import spacy\n",
    "\n",
    "# Load large english language model\n",
    "!python -m spacy download en_core_web_md\n",
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: autocorrect in /home/russell/anaconda3/lib/python3.6/site-packages (0.3.0)\n",
      "\u001b[31mtensorflow 1.11.0 has requirement setuptools<=39.1.0, but you'll have setuptools 40.4.3 which is incompatible.\u001b[0m\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Install and import spelling corrector\n",
    "!pip install autocorrect\n",
    "from autocorrect import spell\n",
    "\n",
    "# Define function to normalize phrase\n",
    "def normalize(text):\n",
    "    return ' '.join([spell(word) for word in text.split()])\n",
    "\n",
    "# Define function to lemmatize phrase\n",
    "def lemmatize(text):\n",
    "    return ' '.join([token.lemma_ for token in nlp(text)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>term_lemma</th>\n",
       "      <th>term_doc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a surge of pride</td>\n",
       "      <td>a surge of pride</td>\n",
       "      <td>(a, surge, of, pride)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abhorrence</td>\n",
       "      <td>abhorrence</td>\n",
       "      <td>(abhorrence)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>admiration</td>\n",
       "      <td>admiration</td>\n",
       "      <td>(admiration)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>adoration</td>\n",
       "      <td>adoration</td>\n",
       "      <td>(adoration)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adrenaline rush</td>\n",
       "      <td>adrenaline rush</td>\n",
       "      <td>(adrenaline, rush)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               term        term_lemma               term_doc\n",
       "0  a surge of pride  a surge of pride  (a, surge, of, pride)\n",
       "1        abhorrence        abhorrence           (abhorrence)\n",
       "2        admiration        admiration           (admiration)\n",
       "3         adoration         adoration            (adoration)\n",
       "4   adrenaline rush   adrenaline rush     (adrenaline, rush)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create dataframe for terms, lemmas, docs\n",
    "term_data = pd.DataFrame([])\n",
    "term_data['term'] = video_term_data.columns\n",
    "term_data['term_lemma'] = term_data['term'].apply(lemmatize)\n",
    "term_data['term_doc'] = term_data['term_lemma'].apply(nlp)\n",
    "term_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOT USED\n",
    "import math\n",
    "\n",
    "def normalize_vector(vector):\n",
    "    magnitude = math.sqrt((vector * vector).sum())\n",
    "    print(magnitude)\n",
    "    return vector / magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOT USED\n",
    "# Define function to select top n vector components\n",
    "def skim(vector, n):\n",
    "    top = vector.sort_values(ascending=False).head(n).index\n",
    "    vector[~vector.index.isin(top)] = 0\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to get term vector from phrase\n",
    "def get_term_vector(phrase, n_terms):\n",
    "    phrase_normal = normalize(phrase)\n",
    "    phrase_lemma = lemmatize(phrase_normal)\n",
    "    phrase_doc = nlp(phrase_lemma)\n",
    "    \n",
    "    term_vector = term_data['term_doc'].apply(phrase_doc.similarity)\n",
    "    term_vector.index = term_data['term']\n",
    "    \n",
    "    top_terms = term_vector.sort_values(ascending=False).head(n_terms).index\n",
    "    term_vector[~term_vector.index.isin(top_terms)] = 0\n",
    "    return term_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "term\n",
      "feeling mad           0.767951\n",
      "feeling pissed off    0.767659\n",
      "feeling scared        0.764903\n",
      "zeal                  0.000000\n",
      "feeling active        0.000000\n",
      "Name: term_doc, dtype: float64\n",
      "Filename\n",
      "2067.mp4    1.738433\n",
      "0070.mp4    1.577848\n",
      "2116.mp4    1.415734\n",
      "2115.mp4    1.273831\n",
      "0226.mp4    1.110918\n",
      "dtype: float64\n",
      "feeling mad           7.679514e-01\n",
      "feeling pissed off    7.676594e-01\n",
      "feeling scared        7.649027e-01\n",
      "disgust               1.776357e-15\n",
      "shock                 1.165734e-15\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# QUALITY CHECK\n",
    "term_vector = get_term_vector(\"I'm feeling pissed\", 3)\n",
    "print(term_vector.sort_values(ascending=False).head())\n",
    "video_vector = t_to_v.dot(term_vector)\n",
    "print(video_vector.sort_values(ascending=False).head())\n",
    "print(v_to_t.dot(video_vector).sort_values(ascending=False).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpret_phrase(phrase, n_terms):\n",
    "    term_vector = get_term_vector(phrase, n_terms)\n",
    "    print('FREE RESPONSE TERMS:\\n', term_vector.sort_values(ascending=False).head(n_terms), '\\n')\n",
    "    \n",
    "    video_vector = normalize(t_to_v.dot(term_vector))\n",
    "    print('VIDEOS:\\n', video_vector.sort_values(ascending=False).head(), '\\n')\n",
    "    \n",
    "    category_vector = v_to_c.dot(video_vector)\n",
    "    print('DISTINCT CATEGORIES:\\n', category_vector.sort_values(ascending=False), '\\n')\n",
    "    \n",
    "    dimension_vector = v_to_d.dot(video_vector) \n",
    "    print('AFFECTIVE DEMENSIONS:\\n', dimension_vector, '\\n')\n",
    "    \n",
    "    distinct_category_vector = v_to_dc.dot(video_vector)\n",
    "    print('DISTINCT CATEGORIES:\\n', distinct_category_vector.sort_values(ascending=False), '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FREE RESPONSE TERMS:\n",
      " term\n",
      "feeling mad       1.000000\n",
      "feeling scared    0.899033\n",
      "feeling silly     0.884864\n",
      "Name: term_doc, dtype: float64 \n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-107-36bc69e0bf7c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minterpret_phrase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"feeling mad\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-106-dac8b069e441>\u001b[0m in \u001b[0;36minterpret_phrase\u001b[0;34m(phrase, n_terms)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'FREE RESPONSE TERMS:\\n'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterm_vector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_terms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mvideo_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_to_v\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mterm_vector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'VIDEOS:\\n'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvideo_vector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-63-5d19c374afbd>\u001b[0m in \u001b[0;36mnormalize\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Define function to normalize phrase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mspell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Define function to lemmatize phrase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   4374\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4375\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4376\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4378\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Series' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "interpret_phrase(\"feeling mad\", 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TAKEWAYS\n",
    "# Not great\n",
    "# doesn't reliably find best match\n",
    "# term dataset covers a very broad range but what I need is more nuance on common feelings\n",
    "# could try universal sentence encoder, but I think that'll be slow and not much better\n",
    "\n",
    "# THINGS TO TRY NEXT\n",
    "# Training a learning model to extract terms effectively\n",
    "# Assuming this is a+ and moving on to how I'd use it (to give me more info on what I'll need)\n",
    "\n",
    "# LATER NOTE\n",
    "# wasn't inverting matricies, still not perfect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
