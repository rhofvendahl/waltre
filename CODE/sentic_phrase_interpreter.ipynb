{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os.path\n",
    "root_path = os.path.dirname(os.getcwd())\n",
    "\n",
    "# Import video data (thanks Cowen & Keltner!)\n",
    "video_data = pd.read_csv(os.path.join(root_path, 'DATA/video_data.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate out 34 emotion category scores, downcase column names\n",
    "# Fraction of respondents who chose from multiple-select\n",
    "video_category_data = video_data.iloc[:, 1:35]\n",
    "video_category_data.index = video_data['Filename']\n",
    "\n",
    "# Separate out 14 affective dimension scores\n",
    "# 1-9 ratings\n",
    "video_dimension_data = video_data.iloc[:, 35:49]\n",
    "video_dimension_data.index = video_data['Filename']\n",
    "\n",
    "# Separate 600 free response term scores\n",
    "# Fraction of respondants who chose from multiple-select dropdown\n",
    "video_term_data = video_data.iloc[:, 49:]\n",
    "video_term_data.index = video_data['Filename']\n",
    "\n",
    "# Select distinct category scores\n",
    "# Subset of category scores\n",
    "video_distinct_category_data = video_data[[\n",
    "    'Admiration',\n",
    "    'Adoration',\n",
    "    'Aesthetic Appreciation',\n",
    "    'Amusement',\n",
    "    'Anger',\n",
    "    'Anxiety',\n",
    "    'Awe',\n",
    "    'Awkwardness',\n",
    "    'Boredom',\n",
    "    'Calmness',\n",
    "    'Confusion',\n",
    "    'Craving',\n",
    "    'Disgust',\n",
    "    'Empathic Pain',\n",
    "    'Entrancement',\n",
    "    'Excitement',\n",
    "    'Fear',\n",
    "    'Horror',\n",
    "    'Interest',\n",
    "    'Joy',\n",
    "    'Nostalgia',\n",
    "    'Relief',\n",
    "    'Romance',\n",
    "    'Sadness',\n",
    "    'Satisfaction',\n",
    "    'sexual desire',\n",
    "    'Surprise'\n",
    "]]\n",
    "video_distinct_category_data.index = video_data['Filename']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data supported matrices (v_to_c.dot(video_vector) = other_vector)\n",
    "v_to_c = video_category_data.transpose()\n",
    "v_to_d = video_dimension_data.transpose()\n",
    "v_to_t = video_term_data.transpose()\n",
    "v_to_dc = video_distinct_category_data.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inverse matrices\n",
    "c_to_v = pd.DataFrame(np.linalg.pinv(v_to_c.values), v_to_c.columns, v_to_c.index)\n",
    "d_to_v = pd.DataFrame(np.linalg.pinv(v_to_d.values), v_to_d.columns, v_to_d.index)\n",
    "t_to_v = pd.DataFrame(np.linalg.pinv(v_to_t.values), v_to_t.columns, v_to_t.index)\n",
    "dc_to_v = pd.DataFrame(np.linalg.pinv(v_to_dc.values), v_to_dc.columns, v_to_dc.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Category inference matrices\n",
    "c_to_d = v_to_d.dot(c_to_v)\n",
    "c_to_t = v_to_t.dot(c_to_v)\n",
    "c_to_dc = v_to_dc.dot(c_to_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimension inference matrices\n",
    "d_to_c = v_to_c.dot(d_to_v)\n",
    "d_to_t = v_to_t.dot(d_to_v)\n",
    "d_to_dc = v_to_dc.dot(d_to_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Term inference matrices\n",
    "t_to_c = v_to_c.dot(t_to_v)\n",
    "t_to_d = v_to_d.dot(t_to_v)\n",
    "t_to_dc = v_to_dc.dot(t_to_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distinct category inference matrices\n",
    "dc_to_c = v_to_c.dot(dc_to_v)\n",
    "dc_to_d = v_to_d.dot(dc_to_v)\n",
    "dc_to_t = v_to_t.dot(dc_to_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in /home/russell/anaconda3/lib/python3.6/site-packages (2.0.12)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/russell/anaconda3/lib/python3.6/site-packages (from spacy) (2.18.4)\n",
      "Requirement already satisfied: thinc<6.11.0,>=6.10.3 in /home/russell/anaconda3/lib/python3.6/site-packages (from spacy) (6.10.3)\n",
      "Requirement already satisfied: murmurhash<0.29,>=0.28 in /home/russell/anaconda3/lib/python3.6/site-packages (from spacy) (0.28.0)\n",
      "Requirement already satisfied: ujson>=1.35 in /home/russell/anaconda3/lib/python3.6/site-packages (from spacy) (1.35)\n",
      "Requirement already satisfied: preshed<2.0.0,>=1.0.0 in /home/russell/anaconda3/lib/python3.6/site-packages (from spacy) (1.0.1)\n",
      "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /home/russell/anaconda3/lib/python3.6/site-packages (from spacy) (0.9.6)\n",
      "Requirement already satisfied: regex==2017.4.5 in /home/russell/anaconda3/lib/python3.6/site-packages (from spacy) (2017.4.5)\n",
      "Requirement already satisfied: cymem<1.32,>=1.30 in /home/russell/anaconda3/lib/python3.6/site-packages (from spacy) (1.31.2)\n",
      "Requirement already satisfied: dill<0.3,>=0.2 in /home/russell/anaconda3/lib/python3.6/site-packages (from spacy) (0.2.8.2)\n",
      "Requirement already satisfied: numpy>=1.7 in /home/russell/.local/lib/python3.6/site-packages (from spacy) (1.15.2)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/russell/anaconda3/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in /home/russell/anaconda3/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.6)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /home/russell/anaconda3/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.22)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/russell/anaconda3/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2018.4.16)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /home/russell/anaconda3/lib/python3.6/site-packages (from thinc<6.11.0,>=6.10.3->spacy) (4.26.0)\n",
      "Requirement already satisfied: msgpack<1.0.0,>=0.5.6 in /home/russell/anaconda3/lib/python3.6/site-packages (from thinc<6.11.0,>=6.10.3->spacy) (0.5.6)\n",
      "Requirement already satisfied: cytoolz<0.10,>=0.9.0 in /home/russell/anaconda3/lib/python3.6/site-packages (from thinc<6.11.0,>=6.10.3->spacy) (0.9.0.1)\n",
      "Requirement already satisfied: msgpack-numpy<1.0.0,>=0.4.1 in /home/russell/anaconda3/lib/python3.6/site-packages (from thinc<6.11.0,>=6.10.3->spacy) (0.4.4.1)\n",
      "Requirement already satisfied: wrapt<1.11.0,>=1.10.0 in /home/russell/anaconda3/lib/python3.6/site-packages (from thinc<6.11.0,>=6.10.3->spacy) (1.10.11)\n",
      "Requirement already satisfied: six<2.0.0,>=1.10.0 in /home/russell/.local/lib/python3.6/site-packages (from thinc<6.11.0,>=6.10.3->spacy) (1.11.0)\n",
      "Requirement already satisfied: toolz>=0.8.0 in /home/russell/anaconda3/lib/python3.6/site-packages (from cytoolz<0.10,>=0.9.0->thinc<6.11.0,>=6.10.3->spacy) (0.9.0)\n",
      "\u001b[31mtensorflow 1.11.0 has requirement setuptools<=39.1.0, but you'll have setuptools 40.4.3 which is incompatible.\u001b[0m\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/russell/anaconda3/lib/python3.6/site-packages/urllib3/connection.py\", line 141, in _new_conn\n",
      "    (self.host, self.port), self.timeout, **extra_kw)\n",
      "  File \"/home/russell/anaconda3/lib/python3.6/site-packages/urllib3/util/connection.py\", line 60, in create_connection\n",
      "    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):\n",
      "  File \"/home/russell/anaconda3/lib/python3.6/socket.py\", line 745, in getaddrinfo\n",
      "    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):\n",
      "socket.gaierror: [Errno -2] Name or service not known\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/russell/anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py\", line 601, in urlopen\n",
      "    chunked=chunked)\n",
      "  File \"/home/russell/anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py\", line 346, in _make_request\n",
      "    self._validate_conn(conn)\n",
      "  File \"/home/russell/anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py\", line 850, in _validate_conn\n",
      "    conn.connect()\n",
      "  File \"/home/russell/anaconda3/lib/python3.6/site-packages/urllib3/connection.py\", line 284, in connect\n",
      "    conn = self._new_conn()\n",
      "  File \"/home/russell/anaconda3/lib/python3.6/site-packages/urllib3/connection.py\", line 150, in _new_conn\n",
      "    self, \"Failed to establish a new connection: %s\" % e)\n",
      "urllib3.exceptions.NewConnectionError: <urllib3.connection.VerifiedHTTPSConnection object at 0x7ff22fead668>: Failed to establish a new connection: [Errno -2] Name or service not known\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/russell/anaconda3/lib/python3.6/site-packages/requests/adapters.py\", line 440, in send\n",
      "    timeout=timeout\n",
      "  File \"/home/russell/anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py\", line 639, in urlopen\n",
      "    _stacktrace=sys.exc_info()[2])\n",
      "  File \"/home/russell/anaconda3/lib/python3.6/site-packages/urllib3/util/retry.py\", line 388, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='raw.githubusercontent.com', port=443): Max retries exceeded with url: /explosion/spacy-models/master/shortcuts-v2.json (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x7ff22fead668>: Failed to establish a new connection: [Errno -2] Name or service not known',))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/russell/anaconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/home/russell/anaconda3/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/home/russell/anaconda3/lib/python3.6/site-packages/spacy/__main__.py\", line 31, in <module>\n",
      "    plac.call(commands[command], sys.argv[1:])\n",
      "  File \"/home/russell/anaconda3/lib/python3.6/site-packages/plac_core.py\", line 328, in call\n",
      "    cmd, result = parser.consume(arglist)\n",
      "  File \"/home/russell/anaconda3/lib/python3.6/site-packages/plac_core.py\", line 207, in consume\n",
      "    return cmd, self.func(*(args + varargs + extraopts), **kwargs)\n",
      "  File \"/home/russell/anaconda3/lib/python3.6/site-packages/spacy/cli/download.py\", line 31, in download\n",
      "    shortcuts = get_json(about.__shortcuts__, \"available shortcuts\")\n",
      "  File \"/home/russell/anaconda3/lib/python3.6/site-packages/spacy/cli/download.py\", line 54, in get_json\n",
      "    r = requests.get(url)\n",
      "  File \"/home/russell/anaconda3/lib/python3.6/site-packages/requests/api.py\", line 72, in get\n",
      "    return request('get', url, params=params, **kwargs)\n",
      "  File \"/home/russell/anaconda3/lib/python3.6/site-packages/requests/api.py\", line 58, in request\n",
      "    return session.request(method=method, url=url, **kwargs)\n",
      "  File \"/home/russell/anaconda3/lib/python3.6/site-packages/requests/sessions.py\", line 508, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/home/russell/anaconda3/lib/python3.6/site-packages/requests/sessions.py\", line 618, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/russell/anaconda3/lib/python3.6/site-packages/requests/adapters.py\", line 508, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPSConnectionPool(host='raw.githubusercontent.com', port=443): Max retries exceeded with url: /explosion/spacy-models/master/shortcuts-v2.json (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x7ff22fead668>: Failed to establish a new connection: [Errno -2] Name or service not known',))\n"
     ]
    }
   ],
   "source": [
    "# SLOW IF FIRST TIME\n",
    "# Install and import Spacy natural language utility\n",
    "!pip install spacy\n",
    "import spacy\n",
    "\n",
    "# Load large english language model\n",
    "!python -m spacy download en_core_web_md\n",
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: autocorrect in /home/russell/anaconda3/lib/python3.6/site-packages (0.3.0)\n",
      "\u001b[31mtensorflow 1.11.0 has requirement setuptools<=39.1.0, but you'll have setuptools 40.4.3 which is incompatible.\u001b[0m\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Install and import spelling corrector\n",
    "!pip install autocorrect\n",
    "from autocorrect import spell\n",
    "\n",
    "# Define function to normalize phrase\n",
    "def normalize(text):\n",
    "    return ' '.join([spell(word) for word in text.split()])\n",
    "\n",
    "# Define function to lemmatize phrase\n",
    "def lemmatize(text):\n",
    "    return ' '.join([token.lemma_ for token in nlp(text)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe for terms, lemmas, docs\n",
    "term_data = pd.DataFrame([])\n",
    "term_data['term'] = video_term_data.columns\n",
    "term_data['term_lemma'] = term_data['term'].apply(lemmatize)\n",
    "term_data['term_doc'] = term_data['term_lemma'].apply(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOT USED\n",
    "import math\n",
    "\n",
    "def normalize_vector(vector):\n",
    "    magnitude = math.sqrt((vector * vector).sum())\n",
    "    print(magnitude)\n",
    "    return vector / magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOT USED\n",
    "# Define function to select top n vector components\n",
    "def skim(vector, n):\n",
    "    top = vector.sort_values(ascending=False).head(n).index\n",
    "    vector[~vector.index.isin(top)] = 0\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to get term vector from phrase\n",
    "def get_term_vector(phrase, n_terms):\n",
    "    phrase_normal = normalize(phrase)\n",
    "    phrase_lemma = lemmatize(phrase_normal)\n",
    "    phrase_doc = nlp(phrase_lemma)\n",
    "    \n",
    "    term_vector = term_data['term_doc'].apply(phrase_doc.similarity)\n",
    "    term_vector.index = term_data['term']\n",
    "    \n",
    "    if term_vector.max() == 1:\n",
    "        n_terms = 1\n",
    "        \n",
    "    top_terms = term_vector.sort_values(ascending=False).head(n_terms).index\n",
    "    term_vector[~term_vector.index.isin(top_terms)] = 0\n",
    "    \n",
    "    return normalize_vector(term_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3282042488044308\n",
      "term\n",
      "feeling mad           0.578188\n",
      "feeling pissed off    0.577968\n",
      "feeling scared        0.575892\n",
      "zeal                  0.000000\n",
      "feeling active        0.000000\n",
      "Name: term_doc, dtype: float64\n",
      "Filename\n",
      "2067.mp4    1.308859\n",
      "0070.mp4    1.187956\n",
      "2116.mp4    1.065901\n",
      "2115.mp4    0.959063\n",
      "0226.mp4    0.836406\n",
      "dtype: float64\n",
      "feeling mad           5.781877e-01\n",
      "feeling pissed off    5.779679e-01\n",
      "feeling scared        5.758924e-01\n",
      "disgust               1.387779e-15\n",
      "shock                 8.881784e-16\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# QUALITY CHECK\n",
    "term_vector = get_term_vector(\"I'm feeling pissed\", 3)\n",
    "print(term_vector.sort_values(ascending=False).head())\n",
    "video_vector = t_to_v.dot(term_vector)\n",
    "print(video_vector.sort_values(ascending=False).head())\n",
    "print(v_to_t.dot(video_vector).sort_values(ascending=False).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpret_phrase(phrase, n_terms):\n",
    "    term_vector = get_term_vector(phrase, n_terms)\n",
    "    print('FREE RESPONSE TERMS:\\n', term_vector.sort_values(ascending=False).head(n_terms), '\\n')\n",
    "    \n",
    "    video_vector = t_to_v.dot(term_vector)\n",
    "    print('VIDEOS:\\n', video_vector.sort_values(ascending=False).head(), '\\n')\n",
    "    \n",
    "    category_vector = v_to_c.dot(video_vector)\n",
    "    print('CATEGORIES:\\n', category_vector.sort_values(ascending=False), '\\n')\n",
    "    \n",
    "    dimension_vector = v_to_d.dot(video_vector) \n",
    "    print('AFFECTIVE DEMENSIONS:\\n', dimension_vector, '\\n')\n",
    "    \n",
    "    distinct_category_vector = v_to_dc.dot(video_vector)\n",
    "    print('DISTINCT CATEGORIES:\\n', distinct_category_vector.sort_values(ascending=False), '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9769273031838307\n",
      "FREE RESPONSE TERMS:\n",
      " term\n",
      "stress     0.783201\n",
      "anxiety    0.621768\n",
      "Name: term_doc, dtype: float64 \n",
      "\n",
      "VIDEOS:\n",
      " Filename\n",
      "1430.mp4    0.431187\n",
      "1838.mp4    0.427992\n",
      "0249.mp4    0.422800\n",
      "1720.mp4    0.403262\n",
      "1079.mp4    0.401742\n",
      "dtype: float64 \n",
      "\n",
      "CATEGORIES:\n",
      " Fear                      0.729677\n",
      "Anxiety                   0.482862\n",
      "Sadness                   0.424617\n",
      "Relief                    0.312148\n",
      "Surprise                  0.217009\n",
      "Excitement                0.180738\n",
      "Joy                       0.111558\n",
      "Awe                       0.102870\n",
      "Triumph                   0.088460\n",
      "Disgust                   0.075353\n",
      "Nostalgia                 0.063591\n",
      "Contempt                  0.054838\n",
      "Disappointment            0.052450\n",
      "Interest                  0.024801\n",
      "Sympathy                  0.007826\n",
      "Entrancement              0.005038\n",
      "Calmness                  0.002734\n",
      "Aesthetic Appreciation   -0.000630\n",
      "Sexual Desire            -0.011239\n",
      "Adoration                -0.013040\n",
      "Satisfaction             -0.014052\n",
      "Envy                     -0.016131\n",
      "Guilt                    -0.016812\n",
      "Pride                    -0.020000\n",
      "Craving                  -0.021568\n",
      "Awkwardness              -0.048404\n",
      "Anger                    -0.055093\n",
      "Boredom                  -0.068111\n",
      "Romance                  -0.083723\n",
      "Confusion                -0.115822\n",
      "Admiration               -0.163125\n",
      "Empathic Pain            -0.198354\n",
      "Amusement                -0.249852\n",
      "Horror                   -0.304397\n",
      "dtype: float64 \n",
      "\n",
      "AFFECTIVE DEMENSIONS:\n",
      " approach        3.081889\n",
      "arousal         9.318051\n",
      "attention      10.455509\n",
      "certainty       3.512235\n",
      "commitment      8.897166\n",
      "control         4.746507\n",
      "dominance       5.846032\n",
      "effort          2.372947\n",
      "fairness        7.321776\n",
      "identity        5.817220\n",
      "obstruction     4.705046\n",
      "safety          2.277168\n",
      "upswing        11.575753\n",
      "valence         6.077385\n",
      "dtype: float64 \n",
      "\n",
      "DISTINCT CATEGORIES:\n",
      " Fear                      7.296772e-01\n",
      "Anxiety                   4.828618e-01\n",
      "Sadness                   4.246167e-01\n",
      "Relief                    3.121482e-01\n",
      "Surprise                  2.170086e-01\n",
      "Excitement                1.807384e-01\n",
      "Joy                       1.115582e-01\n",
      "Awe                       1.028697e-01\n",
      "Disgust                   7.535252e-02\n",
      "Nostalgia                 6.359068e-02\n",
      "Interest                  2.480099e-02\n",
      "Entrancement              5.038140e-03\n",
      "Calmness                  2.734011e-03\n",
      "sexual desire            -2.255141e-16\n",
      "Aesthetic Appreciation   -6.300694e-04\n",
      "Adoration                -1.304036e-02\n",
      "Satisfaction             -1.405186e-02\n",
      "Craving                  -2.156842e-02\n",
      "Awkwardness              -4.840382e-02\n",
      "Anger                    -5.509279e-02\n",
      "Boredom                  -6.811130e-02\n",
      "Romance                  -8.372294e-02\n",
      "Confusion                -1.158218e-01\n",
      "Admiration               -1.631247e-01\n",
      "Empathic Pain            -1.983544e-01\n",
      "Amusement                -2.498520e-01\n",
      "Horror                   -3.043966e-01\n",
      "dtype: float64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "interpret_phrase(\"I'm stressed\", 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TAKEWAYS\n",
    "# Not great\n",
    "# doesn't reliably find best match\n",
    "# term dataset covers a very broad range but what I need is more nuance on common feelings\n",
    "# could try universal sentence encoder, but I think that'll be slow and not much better\n",
    "\n",
    "# THINGS TO TRY NEXT\n",
    "# Training a learning model to extract terms effectively\n",
    "# Assuming this is a+ and moving on to how I'd use it (to give me more info on what I'll need)\n",
    "\n",
    "# LATER NOTE\n",
    "# wasn't inverting matricies, still not perfect\n",
    "\n",
    "# THEORY\n",
    "# Could be that it's giving the most likely analysis given base rate likelihood of various things?\n",
    "# How could I account for that - subtract the average vector?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_term_vector = v_to_t.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9799621013450808"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PRETTY SWEET QUALITY CHECK\n",
    "# The mean term vector is the result of watching each video 1/2000 times, sorta\n",
    "t_to_v.dot(mean_term_vector).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpret_phrases(phrases):\n",
    "    n_terms = 2\n",
    "    \n",
    "    term_vectors = pd.DataFrame([])\n",
    "    video_vectors = pd.DataFrame([])\n",
    "    dimension_vectors = pd.DataFrame([])\n",
    "    distinct_category_vectors = pd.DataFrame([])\n",
    "    \n",
    "    n = 1\n",
    "    for phrase in phrases:\n",
    "        phrase_n = 'phrase_' + str(n)\n",
    "        \n",
    "        term_vectors[phrase_n] = get_term_vector(phrase, n_terms)\n",
    "        video_vectors[phrase_n] = t_to_v.dot(term_vector)\n",
    "        dimension_vectors[phrase_n] = v_to_d.dot(video_vector)\n",
    "        distinct_category_vectors[phrase_n] = v_to_dc.dot(video_vector)\n",
    "        n += 1\n",
    "        \n",
    "    term_vectors['mean'] = term_vectors.mean(axis=1)\n",
    "    video_vectors['mean'] = video_vectors.mean(axis=1)\n",
    "    dimension_vectors['mean'] = dimension_vectors.mean(axis=1)\n",
    "    distinct_category_vectors['mean'] = distinct_category_vectors.mean(axis=1)\n",
    "    \n",
    "    term_vectors = term_vectors.round(2)\n",
    "    video_vectors = video_vectors.round(2)\n",
    "    dimension_vectors = dimension_vectors.round(2)\n",
    "    distinct_category_vectors = distinct_category_vectors.round(2)\n",
    "\n",
    "    print('FREE RESPONSE TERMS:\\n', term_vectors.sort_values(by='mean', ascending=False).head(len(phrases) * n_terms), '\\n')\n",
    "    print('VIDEOS:\\n', video_vectors.sort_values(by='mean', ascending=False).head(), '\\n')\n",
    "    print('AFFECTIVE DEMENSIONS:\\n', dimension_vectors, '\\n')\n",
    "    print('DISTINCT CATEGORIES:\\n', distinct_category_vectors.sort_values(by='mean', ascending=False), '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1915820976840932\n",
      "1.0913203285671425\n",
      "1.0441569909036765\n",
      "FREE RESPONSE TERMS:\n",
      "                       phrase_1  phrase_2  phrase_3  mean\n",
      "term                                                    \n",
      "feeling scared            0.71      0.00      0.00  0.24\n",
      "feeling overwhelmed       0.71      0.00      0.00  0.24\n",
      "feeling overjoyed         0.00      0.00      0.71  0.24\n",
      "feeling apprehensive      0.00      0.00      0.71  0.24\n",
      "feeling alone             0.00      0.72      0.00  0.24\n",
      "feeling important         0.00      0.70      0.00  0.23 \n",
      "\n",
      "VIDEOS:\n",
      "           phrase_1  phrase_2  phrase_3  mean\n",
      "Filename                                    \n",
      "2067.mp4      1.31      1.31      1.31  1.31\n",
      "0070.mp4      1.19      1.19      1.19  1.19\n",
      "2116.mp4      1.07      1.07      1.07  1.07\n",
      "2115.mp4      0.96      0.96      0.96  0.96\n",
      "0226.mp4      0.84      0.84      0.84  0.84 \n",
      "\n",
      "AFFECTIVE DEMENSIONS:\n",
      "              phrase_1  phrase_2  phrase_3  mean\n",
      "approach         0.98      0.98      0.98  0.98\n",
      "arousal          3.80      3.80      3.80  3.80\n",
      "attention        4.09      4.09      4.09  4.09\n",
      "certainty       -2.00     -2.00     -2.00 -2.00\n",
      "commitment      -0.08     -0.08     -0.08 -0.08\n",
      "control         -4.13     -4.13     -4.13 -4.13\n",
      "dominance        0.17      0.17      0.17  0.17\n",
      "effort           2.46      2.46      2.46  2.46\n",
      "fairness        -0.37     -0.37     -0.37 -0.37\n",
      "identity        -0.69     -0.69     -0.69 -0.69\n",
      "obstruction     -2.03     -2.03     -2.03 -2.03\n",
      "safety          -5.05     -5.05     -5.05 -5.05\n",
      "upswing         -1.14     -1.14     -1.14 -1.14\n",
      "valence          2.97      2.97      2.97  2.97 \n",
      "\n",
      "DISTINCT CATEGORIES:\n",
      "                         phrase_1  phrase_2  phrase_3  mean\n",
      "Satisfaction                0.73      0.73      0.73  0.73\n",
      "Disgust                     0.41      0.41      0.41  0.41\n",
      "Anger                       0.37      0.37      0.37  0.37\n",
      "Amusement                   0.36      0.36      0.36  0.36\n",
      "Sadness                     0.24      0.24      0.24  0.24\n",
      "Relief                      0.24      0.24      0.24  0.24\n",
      "Admiration                  0.18      0.18      0.18  0.18\n",
      "Nostalgia                   0.18      0.18      0.18  0.18\n",
      "Adoration                   0.14      0.14      0.14  0.14\n",
      "Empathic Pain               0.12      0.12      0.12  0.12\n",
      "Romance                     0.11      0.11      0.11  0.11\n",
      "Excitement                  0.08      0.08      0.08  0.08\n",
      "Surprise                    0.07      0.07      0.07  0.07\n",
      "Aesthetic Appreciation      0.07      0.07      0.07  0.07\n",
      "Calmness                    0.07      0.07      0.07  0.07\n",
      "Joy                         0.07      0.07      0.07  0.07\n",
      "Fear                        0.04      0.04      0.04  0.04\n",
      "Craving                     0.03      0.03      0.03  0.03\n",
      "sexual desire               0.00      0.00      0.00  0.00\n",
      "Entrancement               -0.08     -0.08     -0.08 -0.08\n",
      "Awe                        -0.10     -0.10     -0.10 -0.10\n",
      "Awkwardness                -0.16     -0.16     -0.16 -0.16\n",
      "Boredom                    -0.19     -0.19     -0.19 -0.19\n",
      "Horror                     -0.40     -0.40     -0.40 -0.40\n",
      "Interest                   -0.46     -0.46     -0.46 -0.46\n",
      "Anxiety                    -0.56     -0.56     -0.56 -0.56\n",
      "Confusion                  -0.78     -0.78     -0.78 -0.78 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "interpret_phrases([\"I feel stressed\", \"I'm feeling better\", \"I'm feeling hopeful\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thank you for using SenticNet 5!\n",
    "\n",
    "Please acknowledge the authors by citing the following publication in any research work or presentation containing results obtained in whole or in part through the use of SenticNet 5:\n",
    "\n",
    "E Cambria, S Poria, D Hazarika, K Kwok. SenticNet 5: Discovering conceptual primitives for sentiment analysis by means of context embeddings. In: AAAI, pp. 1795-1802 (2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#senticnet['concept_name'] = ['pleasantness_value', 'attention_value', 'sensitivity_value', 'aptitude_value', 'primary_mood', 'secondary_mood', 'polarity_label', 'polarity_value', 'semantics1', 'semantics2', 'semantics3', 'semantics4', 'semantics5']\n",
    "%run '../DATA/senticnet5.py'\n",
    "\n",
    "# rename loaded dictionary\n",
    "senticnet_dict = senticnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>concept_name</th>\n",
       "      <th>pleasantness_value</th>\n",
       "      <th>attention_value</th>\n",
       "      <th>sensitivity_value</th>\n",
       "      <th>aptitude_value</th>\n",
       "      <th>primary_mood</th>\n",
       "      <th>secondary_mood</th>\n",
       "      <th>polarity_label</th>\n",
       "      <th>polarity_value</th>\n",
       "      <th>semantics1</th>\n",
       "      <th>semantics2</th>\n",
       "      <th>semantics3</th>\n",
       "      <th>semantics4</th>\n",
       "      <th>semantics5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a_little</td>\n",
       "      <td>-0.99</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.70</td>\n",
       "      <td>#sadness</td>\n",
       "      <td>#disgust</td>\n",
       "      <td>negative</td>\n",
       "      <td>-0.84</td>\n",
       "      <td>least</td>\n",
       "      <td>little</td>\n",
       "      <td>small_amount</td>\n",
       "      <td>shortage</td>\n",
       "      <td>scarce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a_little_hungry</td>\n",
       "      <td>0.757</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>#joy</td>\n",
       "      <td>#joy</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.757</td>\n",
       "      <td>get_full</td>\n",
       "      <td>hunger_go_away</td>\n",
       "      <td>feel_full</td>\n",
       "      <td>hunger</td>\n",
       "      <td>full</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a_little_specific</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.133</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>0.126</td>\n",
       "      <td>#interest</td>\n",
       "      <td>#admiration</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.06</td>\n",
       "      <td>clan</td>\n",
       "      <td>happy_together</td>\n",
       "      <td>many_people</td>\n",
       "      <td>aunt_uncle</td>\n",
       "      <td>human_group</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a_lot</td>\n",
       "      <td>0.277</td>\n",
       "      <td>0.161</td>\n",
       "      <td>0</td>\n",
       "      <td>0.337</td>\n",
       "      <td>#joy</td>\n",
       "      <td>#admiration</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.258</td>\n",
       "      <td>many</td>\n",
       "      <td>plenty</td>\n",
       "      <td>big_amount</td>\n",
       "      <td>abundant</td>\n",
       "      <td>good_number</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a_lot_of_books</td>\n",
       "      <td>0</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0</td>\n",
       "      <td>0.066</td>\n",
       "      <td>#interest</td>\n",
       "      <td>#admiration</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.071</td>\n",
       "      <td>library</td>\n",
       "      <td>old_testament</td>\n",
       "      <td>cook_book</td>\n",
       "      <td>magazine</td>\n",
       "      <td>librarian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        concept_name pleasantness_value attention_value sensitivity_value  \\\n",
       "0           a_little              -0.99               0                 0   \n",
       "1    a_little_hungry              0.757               0                 0   \n",
       "2  a_little_specific              0.089           0.133             -0.10   \n",
       "3              a_lot              0.277           0.161                 0   \n",
       "4     a_lot_of_books                  0           0.076                 0   \n",
       "\n",
       "  aptitude_value primary_mood secondary_mood polarity_label polarity_value  \\\n",
       "0          -0.70     #sadness       #disgust       negative          -0.84   \n",
       "1              0         #joy           #joy       positive          0.757   \n",
       "2          0.126    #interest    #admiration       positive           0.06   \n",
       "3          0.337         #joy    #admiration       positive          0.258   \n",
       "4          0.066    #interest    #admiration       positive          0.071   \n",
       "\n",
       "  semantics1      semantics2    semantics3  semantics4   semantics5  \n",
       "0      least          little  small_amount    shortage       scarce  \n",
       "1   get_full  hunger_go_away     feel_full      hunger         full  \n",
       "2       clan  happy_together   many_people  aunt_uncle  human_group  \n",
       "3       many          plenty    big_amount    abundant  good_number  \n",
       "4    library   old_testament     cook_book    magazine    librarian  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# From file\n",
    "senticnet_columns = ['concept_name', 'pleasantness_value', 'attention_value', 'sensitivity_value', 'aptitude_value', 'primary_mood', 'secondary_mood', 'polarity_label', 'polarity_value', 'semantics1', 'semantics2', 'semantics3', 'semantics4', 'semantics5']\n",
    "\n",
    "# Dict to 2d array\n",
    "senticnet_data = [[concept] + senticnet_dict[concept] for concept in senticnet_dict]\n",
    "\n",
    "# Create senticnet dataframe\n",
    "senticnet = pd.DataFrame(data=senticnet_data, columns=senticnet_columns)\n",
    "\n",
    "# Display\n",
    "print(senticnet.shape)\n",
    "senticnet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
