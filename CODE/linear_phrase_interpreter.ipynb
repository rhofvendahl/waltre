{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Admiration</th>\n",
       "      <th>Adoration</th>\n",
       "      <th>Aesthetic Appreciation</th>\n",
       "      <th>Amusement</th>\n",
       "      <th>Anger</th>\n",
       "      <th>Anxiety</th>\n",
       "      <th>Awe</th>\n",
       "      <th>Awkwardness</th>\n",
       "      <th>Boredom</th>\n",
       "      <th>...</th>\n",
       "      <th>vitality</th>\n",
       "      <th>vulnerability</th>\n",
       "      <th>warmth</th>\n",
       "      <th>weakness</th>\n",
       "      <th>weariness</th>\n",
       "      <th>wonder</th>\n",
       "      <th>worry</th>\n",
       "      <th>wrath</th>\n",
       "      <th>yearning</th>\n",
       "      <th>zeal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001.mp4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002.mp4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.25000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0003.mp4</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.66667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0004.mp4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.75000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.11111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0005.mp4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333330</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.11111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 649 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Filename  Admiration  Adoration  Aesthetic Appreciation  Amusement  \\\n",
       "0  0001.mp4    0.000000        0.0                0.083333    0.00000   \n",
       "1  0002.mp4    0.000000        0.0                0.000000    0.25000   \n",
       "2  0003.mp4    0.083333        0.0                0.083333    0.66667   \n",
       "3  0004.mp4    0.000000        0.0                0.000000    0.75000   \n",
       "4  0005.mp4    0.000000        0.0                0.000000    0.00000   \n",
       "\n",
       "      Anger   Anxiety       Awe  Awkwardness   Boredom  ...   vitality  \\\n",
       "0  0.083333  0.083333  0.083333     0.000000  0.000000  ...        0.0   \n",
       "1  0.000000  0.000000  0.000000     0.000000  0.083333  ...        0.0   \n",
       "2  0.000000  0.000000  0.000000     0.083333  0.000000  ...        0.0   \n",
       "3  0.000000  0.000000  0.000000     0.083333  0.000000  ...        0.0   \n",
       "4  0.000000  0.333330  0.000000     0.000000  0.000000  ...        0.0   \n",
       "\n",
       "   vulnerability  warmth  weakness  weariness  wonder    worry  wrath  \\\n",
       "0            0.0     0.0       0.0    0.00000     0.0  0.00000    0.0   \n",
       "1            0.0     0.0       0.0    0.00000     0.0  0.00000    0.0   \n",
       "2            0.0     0.0       0.0    0.00000     0.0  0.00000    0.0   \n",
       "3            0.0     0.0       0.0    0.11111     0.0  0.00000    0.0   \n",
       "4            0.0     0.0       0.0    0.00000     0.0  0.11111    0.0   \n",
       "\n",
       "   yearning  zeal  \n",
       "0       0.0   0.0  \n",
       "1       0.0   0.0  \n",
       "2       0.0   0.0  \n",
       "3       0.0   0.0  \n",
       "4       0.0   0.0  \n",
       "\n",
       "[5 rows x 649 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os.path\n",
    "root_path = os.path.dirname(os.getcwd())\n",
    "\n",
    "# Import video data (thanks Cowen & Keltner!)\n",
    "video_data = pd.read_csv(os.path.join(root_path, 'DATA/video_data.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate out 34 emotion category scores, downcase column names\n",
    "# Fraction of respondents who chose from multiple-select\n",
    "video_category_data = video_data.iloc[:, 1:35]\n",
    "video_category_data.index = video_data['Filename']\n",
    "\n",
    "# Separate out 14 affective dimension scores\n",
    "# 1-9 ratings\n",
    "video_dimension_data = video_data.iloc[:, 35:49]\n",
    "video_dimension_data.index = video_data['Filename']\n",
    "\n",
    "# Separate 600 free response term scores\n",
    "# Fraction of respondants who chose from multiple-select dropdown\n",
    "video_term_data = video_data.iloc[:, 49:]\n",
    "video_term_data.index = video_data['Filename']\n",
    "\n",
    "# Select distinct category scores\n",
    "# Subset of category scores\n",
    "video_distinct_category_data = video_data[[\n",
    "    'Admiration',\n",
    "    'Adoration',\n",
    "    'Aesthetic Appreciation',\n",
    "    'Amusement',\n",
    "    'Anger',\n",
    "    'Anxiety',\n",
    "    'Awe',\n",
    "    'Awkwardness',\n",
    "    'Boredom',\n",
    "    'Calmness',\n",
    "    'Confusion',\n",
    "    'Craving',\n",
    "    'Disgust',\n",
    "    'Empathic Pain',\n",
    "    'Entrancement',\n",
    "    'Excitement',\n",
    "    'Fear',\n",
    "    'Horror',\n",
    "    'Interest',\n",
    "    'Joy',\n",
    "    'Nostalgia',\n",
    "    'Relief',\n",
    "    'Romance',\n",
    "    'Sadness',\n",
    "    'Satisfaction',\n",
    "    'sexual desire',\n",
    "    'Surprise'\n",
    "]]\n",
    "video_distinct_category_data.index = video_data['Filename']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data supported matrices (v_to_c.dot(video_vector) = other_vector)\n",
    "v_to_c = video_category_data.transpose()\n",
    "v_to_d = video_dimension_data.transpose()\n",
    "v_to_t = video_term_data.transpose()\n",
    "v_to_dc = video_distinct_category_data.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inverse matrices\n",
    "c_to_v = pd.DataFrame(np.linalg.pinv(v_to_c.values), v_to_c.columns, v_to_c.index)\n",
    "d_to_v = pd.DataFrame(np.linalg.pinv(v_to_d.values), v_to_d.columns, v_to_d.index)\n",
    "t_to_v = pd.DataFrame(np.linalg.pinv(v_to_t.values), v_to_t.columns, v_to_t.index)\n",
    "dc_to_v = pd.DataFrame(np.linalg.pinv(v_to_dc.values), v_to_dc.columns, v_to_dc.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Category inference matrices\n",
    "c_to_d = v_to_d.dot(c_to_v)\n",
    "c_to_t = v_to_t.dot(c_to_v)\n",
    "c_to_dc = v_to_dc.dot(c_to_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimension inference matrices\n",
    "d_to_c = v_to_c.dot(d_to_v)\n",
    "d_to_t = v_to_t.dot(d_to_v)\n",
    "d_to_dc = v_to_dc.dot(d_to_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Term inference matrices\n",
    "t_to_c = v_to_c.dot(t_to_v)\n",
    "t_to_d = v_to_d.dot(t_to_v)\n",
    "t_to_dc = v_to_dc.dot(t_to_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distinct category inference matrices\n",
    "dc_to_c = v_to_c.dot(dc_to_v)\n",
    "dc_to_d = v_to_d.dot(dc_to_v)\n",
    "dc_to_t = v_to_t.dot(dc_to_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in /home/russell/anaconda3/lib/python3.6/site-packages (2.0.12)\n",
      "Requirement already satisfied: numpy>=1.7 in /home/russell/.local/lib/python3.6/site-packages (from spacy) (1.15.2)\n",
      "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /home/russell/anaconda3/lib/python3.6/site-packages (from spacy) (0.9.6)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/russell/anaconda3/lib/python3.6/site-packages (from spacy) (2.18.4)\n",
      "Requirement already satisfied: murmurhash<0.29,>=0.28 in /home/russell/anaconda3/lib/python3.6/site-packages (from spacy) (0.28.0)\n",
      "Requirement already satisfied: regex==2017.4.5 in /home/russell/anaconda3/lib/python3.6/site-packages (from spacy) (2017.4.5)\n",
      "Requirement already satisfied: dill<0.3,>=0.2 in /home/russell/anaconda3/lib/python3.6/site-packages (from spacy) (0.2.8.2)\n",
      "Requirement already satisfied: thinc<6.11.0,>=6.10.3 in /home/russell/anaconda3/lib/python3.6/site-packages (from spacy) (6.10.3)\n",
      "Requirement already satisfied: preshed<2.0.0,>=1.0.0 in /home/russell/anaconda3/lib/python3.6/site-packages (from spacy) (1.0.1)\n",
      "Requirement already satisfied: ujson>=1.35 in /home/russell/anaconda3/lib/python3.6/site-packages (from spacy) (1.35)\n",
      "Requirement already satisfied: cymem<1.32,>=1.30 in /home/russell/anaconda3/lib/python3.6/site-packages (from spacy) (1.31.2)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/russell/anaconda3/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in /home/russell/anaconda3/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.6)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /home/russell/anaconda3/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.22)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/russell/anaconda3/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2018.4.16)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /home/russell/anaconda3/lib/python3.6/site-packages (from thinc<6.11.0,>=6.10.3->spacy) (4.26.0)\n",
      "Requirement already satisfied: msgpack-numpy<1.0.0,>=0.4.1 in /home/russell/anaconda3/lib/python3.6/site-packages (from thinc<6.11.0,>=6.10.3->spacy) (0.4.4.1)\n",
      "Requirement already satisfied: six<2.0.0,>=1.10.0 in /home/russell/.local/lib/python3.6/site-packages (from thinc<6.11.0,>=6.10.3->spacy) (1.11.0)\n",
      "Requirement already satisfied: msgpack<1.0.0,>=0.5.6 in /home/russell/anaconda3/lib/python3.6/site-packages (from thinc<6.11.0,>=6.10.3->spacy) (0.5.6)\n",
      "Requirement already satisfied: cytoolz<0.10,>=0.9.0 in /home/russell/anaconda3/lib/python3.6/site-packages (from thinc<6.11.0,>=6.10.3->spacy) (0.9.0.1)\n",
      "Requirement already satisfied: wrapt<1.11.0,>=1.10.0 in /home/russell/anaconda3/lib/python3.6/site-packages (from thinc<6.11.0,>=6.10.3->spacy) (1.10.11)\n",
      "Requirement already satisfied: toolz>=0.8.0 in /home/russell/anaconda3/lib/python3.6/site-packages (from cytoolz<0.10,>=0.9.0->thinc<6.11.0,>=6.10.3->spacy) (0.9.0)\n",
      "\u001b[31mtensorflow 1.11.0 has requirement setuptools<=39.1.0, but you'll have setuptools 40.4.3 which is incompatible.\u001b[0m\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: en_core_web_md==2.0.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_md-2.0.0/en_core_web_md-2.0.0.tar.gz#egg=en_core_web_md==2.0.0 in /home/russell/anaconda3/lib/python3.6/site-packages (2.0.0)\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\n",
      "\u001b[93m    Linking successful\u001b[0m\n",
      "    /home/russell/anaconda3/lib/python3.6/site-packages/en_core_web_md -->\n",
      "    /home/russell/anaconda3/lib/python3.6/site-packages/spacy/data/en_core_web_md\n",
      "\n",
      "    You can now load the model via spacy.load('en_core_web_md')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SLOW IF FIRST TIME\n",
    "# Install and import Spacy natural language utility\n",
    "!pip install spacy\n",
    "import spacy\n",
    "\n",
    "# Load large english language model\n",
    "!python -m spacy download en_core_web_md\n",
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: autocorrect in /home/russell/anaconda3/lib/python3.6/site-packages (0.3.0)\r\n"
     ]
    }
   ],
   "source": [
    "# Install and import spelling corrector\n",
    "!pip install autocorrect\n",
    "from autocorrect import spell\n",
    "\n",
    "# Define function to normalize phrase\n",
    "def normalize(text):\n",
    "    return ' '.join([spell(word) for word in text.split()])\n",
    "\n",
    "# Define function to lemmatize phrase\n",
    "def lemmatize(text):\n",
    "    return ' '.join([token.lemma_ for token in nlp(text)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe for terms, lemmas, docs\n",
    "term_data = pd.DataFrame([])\n",
    "term_data['term'] = video_term_data.columns\n",
    "term_data['term_lemma'] = term_data['term'].apply(lemmatize)\n",
    "term_data['term_doc'] = term_data['term_lemma'].apply(nlp)\n",
    "term_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOT USED\n",
    "import math\n",
    "\n",
    "def normalize_vector(vector):\n",
    "    magnitude = math.sqrt((vector * vector).sum())\n",
    "    print(magnitude)\n",
    "    return vector / magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to get term vector from phrase\n",
    "def get_term_vector(phrase, n_terms):\n",
    "    phrase_normal = normalize(phrase)\n",
    "    phrase_lemma = lemmatize(phrase_normal)\n",
    "    phrase_doc = nlp(phrase_lemma)\n",
    "    \n",
    "    term_vector = term_data['term_doc'].apply(phrase_doc.similarity)\n",
    "    term_vector.index = term_data['term']\n",
    "    \n",
    "    top_terms = term_vector.sort_values(ascending=False).head(n_terms).index\n",
    "    term_vector[~term_vector.index.isin(top_terms)] = 0\n",
    "    return term_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpret_phrase(phrase, n_terms):\n",
    "    term_vector = get_term_vector(phrase, n_terms)\n",
    "    print('FREE RESPONSE TERMS:\\n', term_vector.sort_values(ascending=False).head(n_terms), '\\n')\n",
    "    \n",
    "    video_vector = t_to_v.dot(term_vector)\n",
    "    print('VIDEOS:\\n', video_vector.sort_values(ascending=False).head(), '\\n')\n",
    "    \n",
    "    category_vector = v_to_c.dot(video_vector)\n",
    "    print('DISTINCT CATEGORIES:\\n', category_vector.sort_values(ascending=False), '\\n')\n",
    "    \n",
    "    dimension_vector = v_to_d.dot(video_vector) \n",
    "    print('AFFECTIVE DEMENSIONS:\\n', dimension_vector, '\\n')\n",
    "    \n",
    "    distinct_category_vector = v_to_dc.dot(video_vector)\n",
    "    print('DISTINCT CATEGORIES:\\n', distinct_category_vector.sort_values(ascending=False), '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# QUALITY CHECK\n",
    "term_vector = get_term_vector(\"I'm feeling pissed\", 3)\n",
    "print(term_vector.sort_values(ascending=False).head())\n",
    "video_vector = t_to_v.dot(term_vector)\n",
    "print(video_vector.sort_values(ascending=False).head())\n",
    "print(v_to_t.dot(video_vector).sort_values(ascending=False).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FREE RESPONSE TERMS:\n",
      " term\n",
      "happiness            1.000000\n",
      "extreme happiness    0.817343\n",
      "joy                  0.775831\n",
      "Name: term_doc, dtype: float64 \n",
      "\n",
      "VIDEOS:\n",
      " 1744    0.304397\n",
      "1348    0.176554\n",
      "1187    0.161230\n",
      "1695    0.134951\n",
      "2137    0.129371\n",
      "dtype: float64 \n",
      "\n",
      "DISTINCT CATEGORIES:\n",
      " Joy                       0.949334\n",
      "Adoration                 0.621104\n",
      "Amusement                 0.542459\n",
      "Awe                       0.409756\n",
      "Admiration                0.263923\n",
      "Excitement                0.150091\n",
      "Calmness                  0.141120\n",
      "Nostalgia                 0.133603\n",
      "Sympathy                  0.126788\n",
      "Triumph                   0.076548\n",
      "Interest                  0.052251\n",
      "Envy                      0.046074\n",
      "Aesthetic Appreciation    0.044872\n",
      "Pride                     0.038585\n",
      "Entrancement              0.032333\n",
      "Surprise                  0.024513\n",
      "Romance                   0.017221\n",
      "Boredom                   0.015355\n",
      "Guilt                     0.011599\n",
      "Sadness                   0.011041\n",
      "Fear                      0.007290\n",
      "Disappointment            0.006820\n",
      "Contempt                  0.005909\n",
      "Craving                   0.003947\n",
      "Horror                    0.001416\n",
      "Relief                   -0.002181\n",
      "Sexual Desire            -0.009048\n",
      "Anger                    -0.031782\n",
      "Anxiety                  -0.033290\n",
      "Satisfaction             -0.034140\n",
      "Empathic Pain            -0.044071\n",
      "Awkwardness              -0.066037\n",
      "Confusion                -0.083122\n",
      "Disgust                  -0.094349\n",
      "dtype: float64 \n",
      "\n",
      "AFFECTIVE DEMENSIONS:\n",
      " approach       14.574318\n",
      "arousal        11.545220\n",
      "attention      12.456303\n",
      "certainty      12.826881\n",
      "commitment     13.428517\n",
      "control        14.928314\n",
      "dominance       8.757895\n",
      "effort          2.885588\n",
      "fairness       13.581616\n",
      "identity       11.278305\n",
      "obstruction     5.151228\n",
      "safety         14.276146\n",
      "upswing        14.093369\n",
      "valence        15.668003\n",
      "dtype: float64 \n",
      "\n",
      "DISTINCT CATEGORIES:\n",
      " Joy                       9.493336e-01\n",
      "Adoration                 6.211042e-01\n",
      "Amusement                 5.424590e-01\n",
      "Awe                       4.097558e-01\n",
      "Admiration                2.639227e-01\n",
      "Excitement                1.500911e-01\n",
      "Calmness                  1.411197e-01\n",
      "Nostalgia                 1.336027e-01\n",
      "Interest                  5.225103e-02\n",
      "Aesthetic Appreciation    4.487197e-02\n",
      "Entrancement              3.233345e-02\n",
      "Surprise                  2.451325e-02\n",
      "Romance                   1.722064e-02\n",
      "Boredom                   1.535486e-02\n",
      "Sadness                   1.104090e-02\n",
      "Fear                      7.290462e-03\n",
      "Craving                   3.947130e-03\n",
      "Horror                    1.416409e-03\n",
      "sexual desire            -2.899157e-16\n",
      "Relief                   -2.181177e-03\n",
      "Anger                    -3.178240e-02\n",
      "Anxiety                  -3.329023e-02\n",
      "Satisfaction             -3.414018e-02\n",
      "Empathic Pain            -4.407062e-02\n",
      "Awkwardness              -6.603689e-02\n",
      "Confusion                -8.312155e-02\n",
      "Disgust                  -9.434886e-02\n",
      "dtype: float64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "interpret_phrase(\"happiness\", 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TAKEWAYS\n",
    "# Not great\n",
    "# doesn't reliably find best match\n",
    "# term dataset covers a very broad range but what I need is more nuance on common feelings\n",
    "# could try universal sentence encoder, but I think that'll be slow and not much better\n",
    "\n",
    "# THINGS TO TRY NEXT\n",
    "# Training a learning model to extract terms effectively\n",
    "# Assuming this is a+ and moving on to how I'd use it (to give me more info on what I'll need)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
